{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the model generation results after lora fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "target_reason_folder='llama2-70b-chat-lora/inference'\n",
    "#If the text has multiple paragraphs, merge them into one paragraph\n",
    "reasonList=os.listdir(target_reason_folder)\n",
    "for reason in tqdm(reasonList):\n",
    "    with open(os.path.join(target_reason_folder, reason), 'r') as file:\n",
    "        text = file.read()\n",
    "    if '\\n' in text:\n",
    "        text=text.replace('\\n',' ')\n",
    "    #Remove extra spaces and \"*\" at the beginning\n",
    "    text=text.lstrip()\n",
    "    text=text.replace('* ','')\n",
    "    #Remove extra spaces\n",
    "    text=text.replace('  ',' ')\n",
    "    with open(os.path.join(target_reason_folder, reason), 'w') as file:\n",
    "            file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script processes text files to categorize responsibility in traffic accidents. It identifies mentions of vehicles in the first sentence of each file and categorizes the responsibility accordingly. Files with ambiguous or unclear responsibility are logged separately for further review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def changelabel(name):\n",
    "    folder = 'llama2-70b-chat-lora/generatedResults'\n",
    "    hard2judgetxt='hard2judge.txt'\n",
    "    errorData='errorData.txt'\n",
    "    filename = os.path.join(folder, name)\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Replace patterns for V1 and V2\n",
    "    patterns_v1 = [\"V1\", \"Vehicle #1\", \"Vehicle 1\",\"Vehicle1\",\n",
    "                   \"Vehicle # 1\", \"Vehicle One\", \"Vehicle one\", \"V-1\"]\n",
    "    patterns_v2 = [\"V2\", \"Vehicle #2\", \"Vehicle 2\",\"Vehicle2\",\n",
    "                   \"Vehicle # 2\", \"Vehicle Two\", \"Vehicle two\", \"V-2\"]\n",
    "    patterns_v3 = [\"V3\", \"Vehicle #3\", \"Vehicle 3\",\"Vehicle3\",\n",
    "                   \"Vehicle # 3\", \"Vehicle Three\", \"Vehicle three\", \"V-3\"]\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Process the first sentence based on specific keywords and vehicle patterns\n",
    "    if 'because' in sentences[0]:\n",
    "        sentences0 = sentences[0].split('because')\n",
    "        if any(pattern in sentences0[0] for pattern in patterns_v1):\n",
    "            sentences[0]=\"V1\"\n",
    "        elif any(pattern in sentences0[0] for pattern in patterns_v2):\n",
    "            sentences[0]=\"V2\"\n",
    "        elif any(pattern in sentences0[0] for pattern in patterns_v3):\n",
    "            sentences[0]=\"V3\"\n",
    "        else:\n",
    "            with open(errorData, 'a') as f:\n",
    "                f.write(name+'\\n')\n",
    "        sentences.insert(1,'Because'+sentences0[1])\n",
    "    elif \"due to\" in sentences[0]:\n",
    "        sentences0 = sentences[0].split('due to')\n",
    "        if any(pattern in sentences0[0] for pattern in patterns_v1):\n",
    "            sentences[0]=\"V1\"\n",
    "        elif any(pattern in sentences0[0] for pattern in patterns_v2):\n",
    "            sentences[0]=\"V2\"\n",
    "        elif any(pattern in sentences0[0] for pattern in patterns_v3):\n",
    "            sentences[0]=\"V3\"\n",
    "        else:\n",
    "            with open(errorData, 'a') as f:\n",
    "                f.write(name+'\\n')\n",
    "        sentences.insert(1,'Due to'+sentences0[1]) \n",
    "    elif any(pattern in sentences[0] for pattern in patterns_v1) and any(pattern in sentences[0] for pattern in patterns_v2):\n",
    "        sentences.insert(0,'Neither')\n",
    "        with open(hard2judgetxt, 'a') as f:\n",
    "            f.write(name+'\\n')\n",
    "    elif any(pattern in sentences[0] for pattern in patterns_v1):\n",
    "        sentences[0] = \"V1\"\n",
    "    elif any(pattern in sentences[0] for pattern in patterns_v2):\n",
    "        sentences[0] = \"V2\"\n",
    "    elif any(pattern in sentences[0] for pattern in patterns_v3):\n",
    "        sentences[0] = \"V3\"\n",
    "    else:\n",
    "        with open(errorData, 'a') as f:\n",
    "            sentences.insert(0,'Neither')\n",
    "            f.write(name+'\\n')\n",
    "    # Join the sentences back together\n",
    "    general_processed_text = '. '.join(sentences)\n",
    "    # Save the processed text to a new file\n",
    "    save_folder = 'llama2-70b-chat-lora/responsibility'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    filename = os.path.join(save_folder, name)\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(general_processed_text)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    folder = 'llama2-70b-chat-lora/generatedResults'\n",
    "    file_names = os.listdir(folder)\n",
    "    for file_name in tqdm(file_names):\n",
    "        changelabel(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsibility/Type generated by finetuned models is processed into label and reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def generate_groundtruth(after_label_folder):\n",
    "    for filename in tqdm(os.listdir(after_label_folder)):\n",
    "        with open(os.path.join(after_label_folder, filename), 'r') as afterlabel_file:\n",
    "            try:\n",
    "                afterlabel_content = afterlabel_file.read()\n",
    "                # Process text fields\n",
    "                label, reason = afterlabel_content.split('.', maxsplit=1) # Get the content before the period as the label, and the content after the period as the reason\n",
    "            except ValueError:\n",
    "                print(filename)\n",
    "                continue\n",
    "            reason = reason.lstrip()\n",
    "        \n",
    "        label_folder='llama2-70b-chat-lora/label'\n",
    "        if not os.path.exists(label_folder):\n",
    "            os.makedirs(label_folder)\n",
    "        with open(os.path.join(label_folder, filename), 'w') as label_file:\n",
    "            label_file.write(label)\n",
    "\n",
    "        reason_folder='llama2-70b-chat-lora/reason'\n",
    "        if not os.path.exists(reason_folder):\n",
    "            os.makedirs(reason_folder)\n",
    "        with open(os.path.join(reason_folder, filename), 'w') as reason_file:\n",
    "            reason_file.write(reason)\n",
    "\n",
    "\n",
    "generate_groundtruth(\"llama2-70b-chat-lora/responsibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script processes text files containing descriptions of traffic accidents. It classifies each accident into predefined categories based on the first sentence of the description and extracts the reasoning behind the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Directories for storing types, reasons, and error data\n",
    "type_folder = 'ModelDataset/llama2-70b-chat-lora/type'\n",
    "type_save_folder = 'ModelDataset/llama2-70b-chat-lora/type_label'\n",
    "reason_save_folder = 'ModelDataset/llama2-70b-chat-lora/type_reason'\n",
    "type_errorData = 'type_errorData.txt'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(type_save_folder):\n",
    "    os.makedirs(type_save_folder)\n",
    "if not os.path.exists(reason_save_folder):\n",
    "    os.makedirs(reason_save_folder)\n",
    "\n",
    "# List of files in the type folder\n",
    "typelist = os.listdir(type_folder)\n",
    "\n",
    "# Dictionary mapping type numbers to descriptions\n",
    "typedict = {\n",
    "    '1': 'Single-Vehicle Accident',\n",
    "    '2': 'Backover Collision',\n",
    "    '3': 'Rear-End Collision',\n",
    "    '4': 'Frontal Collision',\n",
    "    '5': 'Front-to-Side Collision',\n",
    "    '6': 'Non-Motorized Vehicle or Pedestrian Crash',\n",
    "    '7': 'Other'\n",
    "}\n",
    "\n",
    "# Process each file\n",
    "for type in tqdm(typelist):\n",
    "    with open(os.path.join(type_folder, type), 'r') as f:\n",
    "        type_content = f.read()\n",
    "    type_label = ''\n",
    "    # Split the content into the first sentence and the rest\n",
    "    if '.' not in type_content:\n",
    "        first_sentence=type_content\n",
    "        other_sentence=type_content\n",
    "    else:\n",
    "        if type_content[0].isdigit():\n",
    "            parts = type_content.split('.', maxsplit=2)\n",
    "            first_sentence = parts[0] + '.' + parts[1]\n",
    "            other_sentence = parts[2] if len(parts) > 2 else ''\n",
    "        else:\n",
    "            first_sentence,other_sentence=type_content.split('.',maxsplit=1)\n",
    "    other_sentence=other_sentence.lstrip()\n",
    "\n",
    "    # Extract the type label from the first sentence\n",
    "    for key, value in typedict.items():\n",
    "        if key in first_sentence:\n",
    "            type_label = key + '.' + value\n",
    "            break\n",
    "\n",
    "    # Write unclassified types to the error data file\n",
    "    if type_label == '':\n",
    "        with open(type_errorData, 'a') as f:\n",
    "            f.write(type + '\\n')\n",
    "\n",
    "    # Save the type label and the reasoning\n",
    "    with open(os.path.join(type_save_folder, type), 'w') as f:\n",
    "        f.write(type_label)\n",
    "    with open(os.path.join(reason_save_folder, type), 'w') as f:\n",
    "        if other_sentence == '':\n",
    "            print(type)\n",
    "        f.write(other_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "type_label_folder='type/GroundTruth/label/test' #Actual labels\n",
    "predict_label_folder='ModelDataset/llama2-70b-chat-lora/type_label' #Predicted labels\n",
    "\n",
    "sum=0\n",
    "accurate=0\n",
    "try:\n",
    "    for label in tqdm(os.listdir(predict_label_folder)):\n",
    "        sum+=1\n",
    "        with open(os.path.join(type_label_folder,label),'r') as f:\n",
    "            type_label=f.read()\n",
    "        with open(os.path.join(predict_label_folder,label),'r') as f:\n",
    "            predict_label=f.read()\n",
    "        if type_label==predict_label:\n",
    "            accurate+=1\n",
    "except FileNotFoundError:\n",
    "    print(label)\n",
    "print(accurate/sum*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
