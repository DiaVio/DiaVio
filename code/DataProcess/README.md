# Classify_Eval.py
The Classify_Eval.py script contains functions to calculate various evaluation metrics for machine learning models. These metrics include accuracy, precision, recall, F1 score (macro and micro-averaged), BERTScore, BLEURT, and NUBIA score. 

# data_Process.ipynb
The data_Process.ipynb Jupyter Notebook is dedicated to processing the results of LoRA fine-tuning.

# Inference.py
The Inference.py script is a versatile tool for utilizing a large language model to generate structured text responses. It includes functions for determining responsibility in traffic accidents and classifying accident types based on detailed descriptions. The script manages model loading, applies LoRA (Low-Rank Adaptation) modifications, and generates responses using customized prompts.

# Lexical_Metrics.py
The Lexical_Metrics.py script incorporates functions for evaluating natural language generation models. It calculates various NLG metrics, including BLEU, METEOR, and ROUGE_L.

# Semantic_Metrics.py
The Semantic_Metrics.py script is designed to calculate various text similarity and quality scores between candidate texts and reference texts. It includes functions for computing BERT scores, BLEURT scores, and Nubia scores. 